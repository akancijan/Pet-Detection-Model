{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2model",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1qn3Oe5u7nve6hQTrJ5MEWFF-5bkMgAnq",
      "authorship_tag": "ABX9TyPIeviYqkFY6gqpdyn/sEfF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akancijan/Pet-Detection-Model/blob/main/TF2model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwzA2Moe-mH9",
        "outputId": "ec1772ac-3abc-4c28-fcea-2d6e7bbaf398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from shutil import copyfile\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "N-AInYs3-vpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "print(os.listdir())"
      ],
      "metadata": {
        "id": "bQ0NDL94BEHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('models') \n",
        "print(os.listdir())"
      ],
      "metadata": {
        "id": "nlW6U_uey8Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split pictures and XML files in seperate folders\n",
        "\n",
        "# src_directory = '/content/drive/MyDrive/Diplomski/Asirra_ cat vs dogs'\n",
        "# for file in os.listdir(src_directory):\n",
        "#     if '.jpg' in str(file):\n",
        "#       src_jpg = src_directory + '/' + file\n",
        "#       xml_file = str(file).replace('.jpg','.xml')\n",
        "#       src_xml = src_directory + '/' + xml_file\n",
        "#       dst_dir_img = '/content/drive/MyDrive/Diplomski/customTF2/images/'\n",
        "#       dst_dir_xml = '/content/drive/MyDrive/Diplomski/customTF2/annotations/'\n",
        "#       print(f'src_jpg {src_jpg} ')\n",
        "#       print(f'src_xml {src_xml} ')\n",
        "#       print(f'dst_img {dst_dir_img}')\n",
        "#       print(f'dst_xml {dst_dir_xml}')\n",
        "#       if file.startswith('cat'):\n",
        "#           dst_jpg = dst_dir_img + file\n",
        "#           dst_xml = dst_dir_xml + xml_file\n",
        "#           print(f'Send cat picture to : {dst_jpg}')\n",
        "#           print(f'Send cat xml to : {dst_xml}')\n",
        "#           copyfile(src_jpg, dst_jpg)\n",
        "#           copyfile(src_xml, dst_xml)\n",
        "#       elif file.startswith('dog'):\n",
        "#           dst_jpg =dst_dir_img + file\n",
        "#           dst_xml =dst_dir_xml + xml_file\n",
        "#           print(f'Send dog picture to : {dst_jpg}')\n",
        "#           print(f'Send dog xml to : {dst_xml}')\n",
        "#           copyfile(src_jpg, dst_jpg)\n",
        "#           copyfile(src_xml, dst_xml)"
      ],
      "metadata": {
        "id": "oXmY3zxW_r_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Symbolic link = /content/drive/MyDrive/Diplomski/ is now /mydrive\n",
        "!ln -s /content/drive/MyDrive/Diplomski/ /mydrive\n",
        "!ls /mydrive"
      ],
      "metadata": {
        "id": "wPUsobD8DIVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clone the tensorflow models on the colab cloud vm\n",
        "!git clone --q https://github.com/tensorflow/models.git\n",
        "\n",
        "#navigate to /models/research folder to compile protos\n",
        "%cd models/research\n",
        "\n",
        "# Compile protos.\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# Install TensorFlow Object Detection API.\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install .\n"
      ],
      "metadata": {
        "id": "MgDHvRdcD0Gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing the model builder\n",
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "id": "sEsBAHteE9x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup traning and validation sets\n",
        "#\n",
        "# %cd /mydrive/customTF2/data/\n",
        "\n",
        "# !mkdir test_labels train_labels"
      ],
      "metadata": {
        "id": "fV2fGLlZFqNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #   Note!!!\n",
        "# ### run this once to sort pictures\n",
        "# ### after that you can skip this section \n",
        "# import random\n",
        "# from random import seed\n",
        "# from random import randint\n",
        "\n",
        "# # seed random number generator\n",
        "# seed(1)\n",
        "# # Set aside 20% of labeled pictures for validation of our created model\n",
        "# val_ratio = 0.20\n",
        "# # Sort pictures into test and train directories\n",
        "# # and further sort them by dog/cat subdirectories\n",
        "# src_directory = '/content/drive/MyDrive/Diplomski/customTF2/annotations/'\n",
        "# for file in os.listdir(src_directory):\n",
        "#     if '.xml' in str(file):\n",
        "#       src_xml = src_directory + file\n",
        "#       dst_dir = '/content/drive/MyDrive/Diplomski/customTF2/data/train_labels/'\n",
        "#       print(f'src xml {src_xml}')\n",
        "#       print(f'dst {dst_dir}')\n",
        "#       if random.random() < val_ratio:\n",
        "#           dst_dir = '/content/drive/MyDrive/Diplomski/customTF2/data/test_labels/'\n",
        "#           print(f'random triggered : {dst_dir}')\n",
        "#       if file.startswith('cat'):\n",
        "#           dst_xml = dst_dir + file\n",
        "#           print(f'Send cat xml to : {dst_xml}')\n",
        "#           copyfile(src_xml, dst_xml)\n",
        "\n",
        "#       elif file.startswith('dog'):\n",
        "#           dst_xml = dst_dir + file\n",
        "#           print(f'Send dog xml to : {dst_xml}')\n",
        "#           copyfile(src_xml, dst_xml)"
      ],
      "metadata": {
        "id": "0NwZ_JO4GBHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if training set has about the same amount of cat/dog labels\n",
        "\n",
        "src_directory = '/content/drive/MyDrive/Diplomski/customTF2/data/train_labels/'\n",
        "dog_count=0\n",
        "cat_count=0\n",
        "for file in os.listdir(src_directory):\n",
        "  if 'cat' in str(file):\n",
        "    cat_count+=1\n",
        "  if 'dog' in str(file):\n",
        "    dog_count+=1\n",
        "  \n",
        "\n",
        "print(f'Dogs : {dog_count} Cats {cat_count}')\n",
        "\n",
        "# Check if test set has about the same amount of cat/dog labels\n",
        "\n",
        "src_directory = '/content/drive/MyDrive/Diplomski/customTF2/data/test_labels/'\n",
        "dog_count=0\n",
        "cat_count=0\n",
        "for file in os.listdir(src_directory):\n",
        "  if 'cat' in str(file):\n",
        "    cat_count+=1\n",
        "  if 'dog' in str(file):\n",
        "    dog_count+=1\n",
        "  \n",
        "\n",
        "print(f'Dogs : {dog_count} Cats {cat_count}')"
      ],
      "metadata": {
        "id": "bpf9PDCaH6xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in .xml files to a combined .csv file for record creation\n",
        "def xml_to_csv(path):\n",
        "  classes_names = []\n",
        "  xml_list = []\n",
        "\n",
        "  for xml_file in glob.glob(path + '/*.xml'):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    for member in root.findall('object'):\n",
        "      classes_names.append(member[0].text)\n",
        "      value = (root.find('filename').text  ,   \n",
        "               int(root.find('size')[0].text),\n",
        "               int(root.find('size')[1].text),\n",
        "               member[0].text,\n",
        "               float(member[4][0].text),\n",
        "               float(member[4][1].text),\n",
        "               float(member[4][2].text),\n",
        "               float(member[4][3].text))\n",
        "      xml_list.append(value)\n",
        "  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "  xml_df = pd.DataFrame(xml_list, columns=column_name) \n",
        "  classes_names = list(set(classes_names))\n",
        "  classes_names.sort()\n",
        "  return xml_df, classes_names\n",
        "\n",
        "for label_path in ['train_labels', 'test_labels']:\n",
        "  image_path = os.path.join(os.getcwd(), label_path)\n",
        "  xml_df, classes = xml_to_csv(label_path)\n",
        "  xml_df.to_csv(f'{label_path}.csv', index=None)\n",
        "  print(f'Successfully converted {label_path} xml to csv.')\n",
        "\n",
        "label_map_path = os.path.join(\"label_map.pbtxt\")\n",
        "pbtxt_content = \"\"\n",
        "\n",
        "for i, class_name in enumerate(classes):\n",
        "    pbtxt_content = (\n",
        "        pbtxt_content\n",
        "        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(i + 1, class_name)\n",
        "    )\n",
        "pbtxt_content = pbtxt_content.strip()\n",
        "with open(label_map_path, \"w\") as f:\n",
        "    f.write(pbtxt_content)\n",
        "    print('Successfully created label_map.pbtxt ')   "
      ],
      "metadata": {
        "id": "Bj93d3hRI84a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /mydrive/customTF2/data"
      ],
      "metadata": {
        "id": "qpb9pvVtKStC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run downloaded script for creation of .record files\n",
        "# Use it twice to create train and test records\n",
        "\n",
        "#For train.record\n",
        "!python /mydrive/customTF2/generate_tfrecord.py train_labels.csv  label_map.pbtxt /mydrive/customTF2/images/ train.record\n",
        "\n",
        "#For test.record\n",
        "!python /mydrive/customTF2/generate_tfrecord.py test_labels.csv  label_map.pbtxt /mydrive/customTF2/images/ test.record\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0NjMP3rJS_R",
        "outputId": "528c99b0-4bdf-4269-8164-34a72ce4e1a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "groups: 100% 898/898 [00:02<00:00, 425.52it/s]\n",
            "Successfully created the TFRecords: /content/drive/MyDrive/Diplomski/customTF2/data/train.record\n",
            "groups: 100% 202/202 [00:00<00:00, 441.54it/s]\n",
            "Successfully created the TFRecords: /content/drive/MyDrive/Diplomski/customTF2/data/test.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the pre-trained model \n",
        "# For this dataset we are using faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz \n",
        "# Download it into the data folder & unzip it.\n",
        "\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n",
        "!tar -xzvf faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Xj9AosdLCc0",
        "outputId": "fe12683d-904f-4dab-a081-912927035d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-22 19:04:59--  http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.6.128, 2607:f8b0:4001:c5a::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.6.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 211996178 (202M) [application/x-tar]\n",
            "Saving to: ‘faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "faster_rcnn_resnet5 100%[===================>] 202.17M  64.2MB/s    in 3.2s    \n",
            "\n",
            "2022-01-22 19:05:02 (64.2 MB/s) - ‘faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz’ saved [211996178/211996178]\n",
            "\n",
            "faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/\n",
            "faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/checkpoint/\n",
            "faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/pipeline.config\n",
            "faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/saved_model/\n",
            "faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/saved_model/variables/\n",
            "faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load tensorboard\n",
        "\n",
        "%load_ext tensorboard         \n",
        "%tensorboard --logdir '/content/drive/MyDrive/Diplomski/customTF2/training'"
      ],
      "metadata": {
        "id": "fOBWuq73L21q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models/research/object_detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P5aSnaAvsa7",
        "outputId": "25526c59-12bc-4fb9-ee95-f1dc71ab7d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/object_detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to downgrade opencv-python-headless package \n",
        "# Higher versions cause an error that prevents the model from training\n",
        "!pip install \"opencv-python-headless<4.3\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLBk8qJ-xN7K",
        "outputId": "65e1e5a0-8d98-40e0-8539-5950d6fc6c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python-headless<4.3\n",
            "  Downloading opencv_python_headless-4.2.0.34-cp37-cp37m-manylinux1_x86_64.whl (21.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.6 MB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless<4.3) (1.19.5)\n",
            "Installing collected packages: opencv-python-headless\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.5.5.62\n",
            "    Uninstalling opencv-python-headless-4.5.5.62:\n",
            "      Successfully uninstalled opencv-python-headless-4.5.5.62\n",
            "Successfully installed opencv-python-headless-4.2.0.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the command below from the content/models/research/object_detection directory\n",
        "\n",
        "# PIPELINE_CONFIG_PATH={path to pipeline config file}\n",
        "# MODEL_DIR={path to model directory}\n",
        "# Example of the python command to run the training process\n",
        "#!python model_main_tf2.py --pipeline_config_path=${PIPELINE_CONFIG_PATH} --model_dir=${MODEL_DIR} --alsologtostderr\n",
        "\n",
        "!python model_main_tf2.py --pipeline_config_path=/mydrive/customTF2/data/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config --model_dir=/mydrive/customTF2/training --alsologtostderr"
      ],
      "metadata": {
        "id": "ambtcPECvu66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Export inference graph\n",
        "!python exporter_main_v2.py --trained_checkpoint_dir=/mydrive/customTF2/training --pipeline_config_path=/mydrive/customTF2/data/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config --output_directory /mydrive/customTF2/data/inference_graph"
      ],
      "metadata": {
        "id": "j2xkJzGCc7Ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Different font-type for labels text\n",
        "!wget https://freefontsdownload.net/download/160187/arial.zip\n",
        "!unzip arial.zip -d .\n",
        "\n",
        "%cd utils/\n",
        "!sed -i \"s/font = ImageFont.truetype('arial.ttf', 24)/font = ImageFont.truetype('arial.ttf', 50)/\" visualization_utils.py\n",
        "%cd .."
      ],
      "metadata": {
        "id": "8yurZoXHsb-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the saved_model\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "IMAGE_SIZE = (16, 8) # Output display size as you want\n",
        "import matplotlib.pyplot as plt\n",
        "PATH_TO_SAVED_MODEL=\"/mydrive/customTF2/data/inference_graph/saved_model\"\n",
        "print('Loading model...', end='')\n",
        "\n",
        "# Load saved model and build the detection function\n",
        "detect_fn=tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "print('Done!')\n",
        "\n",
        "# Loading the label_map\n",
        "category_index=label_map_util.create_category_index_from_labelmap(\"/mydrive/customTF2/data/label_map.pbtxt\",use_display_name=True)\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "\n",
        "    return np.array(Image.open(path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp633skIsvXU",
        "outputId": "2e2d0392-2117-4127-9fe3-1557cffd8a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "# Testing out model on single images\n",
        "\n",
        "image_path = \"/mydrive/customTF2/uploaded_pictures/moki_sunset.jpg\"\n",
        "\n",
        "image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "input_tensor = tf.convert_to_tensor(image_np)\n",
        "# The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# All outputs are batches tensors.\n",
        "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "# We're only interested in the first num_detections.\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_detections,\n",
        "      detections['detection_boxes'],\n",
        "      detections['detection_classes'],\n",
        "      detections['detection_scores'],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=.4, # Adjust this value to set the minimum probability boxes to be classified as True\n",
        "      agnostic_mode=False)\n",
        "\n",
        "\n",
        "#Create indexes list of element with a score > 0.5\n",
        "indexes = [k for k,v in enumerate(detections['detection_scores']) if (v > 0.2)]\n",
        "\n",
        "#Number of entities\n",
        "num_entities = len(indexes)\n",
        "#Extract the class id\n",
        "class_id = itemgetter(*indexes)(detections['detection_classes'])\n",
        "scores = itemgetter(*indexes)(detections['detection_scores'])\n",
        "\n",
        "#Convert the class id in their name\n",
        "class_names = []\n",
        "if num_entities == 1:\n",
        "  class_names.append(category_index[class_id]['name'])\n",
        "  class_name = str(class_names)\n",
        "else:\n",
        "  for i in range(0, len(indexes)):\n",
        "    class_names.append(category_index[class_id[i]]['name'])\n",
        "\n",
        "print(class_names)\n",
        "print(class_id)\n",
        "print(scores)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "plt.figure(figsize=IMAGE_SIZE, dpi=200)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(image_np_with_detections)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "rOJ1oXpb4O2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_dir = \"/mydrive/customTF2/uploaded_pictures/\"\n",
        "# simple version for working with CWD\n",
        "number_of_pictures = 0\n",
        "for file in os.listdir(images_dir):\n",
        "  number_of_pictures += 1\n",
        "print(number_of_pictures)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rwa06xu7D11",
        "outputId": "15e0ce7b-abe5-4454-e508-0f430047a48d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xlsxwriter\n",
        "import xlsxwriter\n",
        "import re\n",
        "\n",
        "report_path = \"/mydrive/customTF2/excel_report\"\n",
        "\n",
        "workbook = xlsxwriter.Workbook(f'{report_path}/guesses4.xlsx')\n",
        "worksheet = workbook.add_worksheet(f'Dog-Cat Guesses')\n",
        "\n",
        "# Column names\n",
        "worksheet.write('A1', 'Picture_ID')\n",
        "worksheet.write('B1', 'Class')\n",
        "worksheet.write('C1', 'Score')\n",
        "worksheet.write('D1', 'Picture_Nr')\n",
        "\n",
        "row_index = 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq8DlLFtxypa",
        "outputId": "73f8b1cd-411a-4fbe-8b9e-4ba061d45f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.7/dist-packages (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rows are equal to \"number_of_pictures\" to form the wanted subplot\n",
        "rows = number_of_pictures\n",
        "columns = 1\n",
        "file_number = 1\n",
        "\n",
        "images_dir_testing = \"/mydrive/customTF2/cat-dog_pictures_with_defined_name/\"\n",
        "\n",
        "for file in os.listdir(images_dir_testing):\n",
        "  image_path = images_dir_testing + file\n",
        "  image_np = load_image_into_numpy_array(image_path)\n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "  input_tensor = tf.convert_to_tensor(image_np)\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "  \n",
        "  detections = detect_fn(input_tensor)\n",
        "  # All outputs are batches tensors.\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "  # We're only interested in the first num_detections.\n",
        "  num_detections = int(detections.pop('num_detections'))\n",
        "  detections = {key: value[0, :num_detections].numpy()\n",
        "                for key, value in detections.items()}\n",
        "  detections['num_detections'] = num_detections\n",
        "  \n",
        "  # detection_classes should be ints.\n",
        "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "  image_np_with_detections = image_np.copy()\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_detections,\n",
        "      detections['detection_boxes'],\n",
        "      detections['detection_classes'],\n",
        "      detections['detection_scores'],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=.4, # Adjust this value to set the minimum probability boxes to be classified as True\n",
        "      agnostic_mode=False)\n",
        "  \n",
        "\n",
        "\n",
        "  try:\n",
        "    #Create indexes list of element with a score > 0.5\n",
        "    indexes = [k for k,v in enumerate(detections['detection_scores']) if (v > 0.5)]\n",
        "\n",
        "    #Number of entities\n",
        "    num_entities = len(indexes)\n",
        "\n",
        "    #Extract the class id\n",
        "    class_id = itemgetter(*indexes)(detections['detection_classes'])\n",
        "    scores = itemgetter(*indexes)(detections['detection_scores'])\n",
        "\n",
        "\n",
        "    #Convert the class id in their name\n",
        "    class_names = []\n",
        "    if num_entities == 1:\n",
        "      class_names.append(category_index[class_id]['name'])\n",
        "      class_names = str(class_names)\n",
        "    else:\n",
        "      for i in range(0, len(indexes)):\n",
        "        class_names.append(category_index[class_id[i]]['name'])\n",
        "        print(str(scores[i]))\n",
        "    \n",
        "  except TypeError:\n",
        "    class_names = []\n",
        "    class_names.append('No cat/dog found')\n",
        "    scores = 0\n",
        "  print(f'Picture number {file_number}')\n",
        "  print(f'Detected classes{class_names}')\n",
        "  print(f'Score : {scores}')\n",
        "  print(f'file : {file}')\n",
        "\n",
        "\n",
        "  # add to xlsx\n",
        "  worksheet.write(f'A{row_index}', file)\n",
        "  worksheet.write(f'B{row_index}', str(class_names))\n",
        "  worksheet.write(f'C{row_index}', str(scores))\n",
        "  worksheet.write(f'D{row_index}', str(file_number))\n",
        "  row_index += 1\n",
        "  #fig.add_subplot(rows,columns,file_number)\n",
        "  file_number+=1\n",
        "  plt.figure(figsize=IMAGE_SIZE)\n",
        "  plt.imshow(image_np_with_detections)\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()\n",
        "\n",
        "workbook.close()"
      ],
      "metadata": {
        "id": "EhRTFtWjMg4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workbook = xlsxwriter.Workbook(f'{report_path}/guesses3_1500_sample.xlsx')\n",
        "worksheet = workbook.add_worksheet(f'Dog-Cat Guesses')\n",
        "\n",
        "# Column names\n",
        "worksheet.write('A1', 'Picture_ID')\n",
        "worksheet.write('B1', 'Class')\n",
        "worksheet.write('C1', 'Score')\n",
        "worksheet.write('D1', 'Picture_Nr')\n",
        "\n",
        "row_index = 2\n",
        "file_number = 1"
      ],
      "metadata": {
        "id": "G5XXky1v9jHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_dir_testing = \"/mydrive/customTF2/1000_test/\"\n",
        "\n",
        "for file in os.listdir(images_dir_testing):\n",
        "  image_path = images_dir_testing + file\n",
        "  image_np = load_image_into_numpy_array(image_path)\n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "  input_tensor = tf.convert_to_tensor(image_np)\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "  \n",
        "  detections = detect_fn(input_tensor)\n",
        "  # All outputs are batches tensors.\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "  # We're only interested in the first num_detections.\n",
        "  num_detections = int(detections.pop('num_detections'))\n",
        "  detections = {key: value[0, :num_detections].numpy()\n",
        "                for key, value in detections.items()}\n",
        "  detections['num_detections'] = num_detections\n",
        "  \n",
        "  # detection_classes should be ints.\n",
        "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "  image_np_with_detections = image_np.copy()\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_detections,\n",
        "      detections['detection_boxes'],\n",
        "      detections['detection_classes'],\n",
        "      detections['detection_scores'],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=.4, # Adjust this value to set the minimum probability boxes to be classified as True\n",
        "      agnostic_mode=False)\n",
        "  \n",
        "\n",
        "\n",
        "  try:\n",
        "    #Create indexes list of element with a score > 0.5\n",
        "    indexes = [k for k,v in enumerate(detections['detection_scores']) if (v > 0.5)]\n",
        "\n",
        "    #Number of entities\n",
        "    num_entities = len(indexes)\n",
        "\n",
        "    #Extract the class id\n",
        "    class_id = itemgetter(*indexes)(detections['detection_classes'])\n",
        "    scores = itemgetter(*indexes)(detections['detection_scores'])\n",
        "\n",
        "\n",
        "    #Convert the class id in their name\n",
        "    class_names = []\n",
        "    if num_entities == 1:\n",
        "      class_names.append(category_index[class_id]['name'])\n",
        "      class_names = str(class_names)\n",
        "    else:\n",
        "      for i in range(0, len(indexes)):\n",
        "        class_names.append(category_index[class_id[i]]['name'])\n",
        "        print(str(scores[i]))\n",
        "    \n",
        "  except TypeError:\n",
        "    class_names = []\n",
        "    class_names.append('No cat/dog found')\n",
        "    scores = 0\n",
        "  print(f'Picture number {file_number}')\n",
        "  print(f'Detected classes{class_names}')\n",
        "  print(f'Score : {scores}')\n",
        "  print(f'file : {file}')\n",
        "\n",
        "\n",
        "  # add to xlsx\n",
        "  worksheet.write(f'A{row_index}', file)\n",
        "  worksheet.write(f'B{row_index}', str(class_names))\n",
        "  worksheet.write(f'C{row_index}', str(scores))\n",
        "  worksheet.write(f'D{row_index}', str(file_number))\n",
        "  row_index += 1\n",
        "  #fig.add_subplot(rows,columns,file_number)\n",
        "  file_number+=1\n",
        "  plt.figure(figsize=IMAGE_SIZE)\n",
        "  plt.imshow(image_np_with_detections)\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()\n",
        "\n",
        "workbook.close()"
      ],
      "metadata": {
        "id": "DvjuCg6U9uQ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}